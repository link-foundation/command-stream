# ğŸ command-stream Benchmark Suite

Comprehensive benchmarking suite that compares command-stream against all major competitors with concrete performance data to justify switching from alternatives.

## ğŸ“Š Overview

This benchmark suite provides **concrete performance data** to help developers make informed decisions when choosing a shell utility library. We compare command-stream against:

- **[execa](https://github.com/sindresorhus/execa)** (98M+ monthly downloads) - Modern process execution
- **[cross-spawn](https://github.com/moxystudio/node-cross-spawn)** (409M+ monthly downloads) - Cross-platform spawning  
- **[ShellJS](https://github.com/shelljs/shelljs)** (35M+ monthly downloads) - Unix shell commands
- **[zx](https://github.com/google/zx)** (4.2M+ monthly downloads) - Google's shell scripting
- **[Bun.$](https://bun.sh/docs/runtime/shell)** (built-in) - Bun's native shell

## ğŸ¯ Benchmark Categories

### 1. ğŸ“¦ Bundle Size Analysis
**Goal:** Compare bundle sizes and dependency footprints

- **Installed size** comparison
- **Gzipped bundle size** estimates  
- **Dependency count** analysis
- **Tree-shaking effectiveness**
- **Memory footprint** at runtime

**Key Metrics:**
- command-stream: ~20KB gzipped
- Competitors: 2KB-400KB+ range
- Zero dependencies vs heavy dependency trees

### 2. âš¡ Performance Benchmarks
**Goal:** Measure execution speed and resource usage

**Test Categories:**
- **Process Spawning Speed** - How fast commands start
- **Streaming vs Buffering** - Memory efficiency with large outputs
- **Pipeline Performance** - Multi-command pipeline speed
- **Concurrent Execution** - Parallel process handling
- **Error Handling Speed** - Exception and error code performance
- **Memory Usage Patterns** - Heap usage during operations

**Key Measurements:**
- Average execution time (ms)
- Memory delta during operations
- 95th/99th percentile performance
- Throughput for streaming operations

### 3. ğŸ§ª Feature Completeness Tests
**Goal:** Validate API compatibility and feature parity

**Test Areas:**
- **Template Literal Support** - `` $`command` `` syntax
- **Real-time Streaming** - Live output processing
- **Async Iteration** - `for await` loop support
- **EventEmitter Pattern** - `.on()` event handling
- **Built-in Commands** - Cross-platform command availability
- **Pipeline Support** - Command chaining capabilities
- **Signal Handling** - SIGINT/SIGTERM management
- **Mixed Patterns** - Combining different usage styles

**Compatibility Matrix:**
- âœ… Full support
- ğŸŸ¡ Limited support  
- âŒ Not supported

### 4. ğŸŒ Real-World Use Cases
**Goal:** Test realistic scenarios and workflows

**Scenarios Tested:**
- **CI/CD Pipeline Simulation** - Typical build/test/deploy workflows
- **Log Processing** - Analyzing large log files with grep/awk
- **File Operations** - Batch file processing and organization  
- **Development Workflows** - Common dev tasks like finding files, counting lines
- **Network Command Handling** - Connectivity checks and remote operations

**Measurements:**
- End-to-end workflow performance
- Error resilience in production scenarios
- Resource usage under realistic loads

## ğŸš€ Quick Start

### Run All Benchmarks
```bash
# Complete benchmark suite (may take 5-10 minutes)
npm run benchmark

# Quick benchmark (features + performance only)
npm run benchmark:quick
```

### Run Individual Suites
```bash
# Bundle size comparison
npm run benchmark:bundle

# Performance tests
npm run benchmark:performance  

# Feature completeness tests
npm run benchmark:features

# Real-world scenarios
npm run benchmark:real-world
```

### Manual Execution
```bash
cd benchmarks

# Run specific benchmark
node bundle-size/bundle-size-benchmark.mjs
node performance/performance-benchmark.mjs  
node features/feature-completeness-benchmark.mjs
node real-world/real-world-benchmark.mjs

# Run comprehensive suite with options
node run-all-benchmarks.mjs --skip-bundle-size --skip-real-world
```

## ğŸ“‹ Results & Reports

### Generated Reports
After running benchmarks, check the `benchmarks/results/` directory:

- **`comprehensive-benchmark-report.html`** - Interactive HTML report
- **`comprehensive-results.json`** - Complete raw data
- **Individual JSON files** - Detailed results for each suite
- **Charts and visualizations** - Performance comparisons

### Understanding Results

**Performance Rankings:**
- ğŸ¥‡ 1st place - Fastest implementation
- ğŸ¥ˆ 2nd place - Good performance  
- ğŸ¥‰ 3rd place - Acceptable performance
- Speed ratios show relative performance (1.00x = baseline)

**Feature Test Results:**
- âœ… **PASS** - Feature works correctly
- âŒ **FAIL** - Feature missing or broken
- Success rate shows overall compatibility

**Bundle Size Rankings:**
- Ranked by gzipped size (smaller = better)
- Includes dependency impact
- Memory usage estimates

## ğŸ”§ Configuration

### Environment Variables
```bash
# Enable verbose logging
export COMMAND_STREAM_VERBOSE=true

# Run in CI mode
export CI=true
```

### Customizing Benchmarks
Edit benchmark files to adjust:
- **Iteration counts** - More iterations = more accurate results
- **Warmup rounds** - Reduce JIT compilation effects  
- **Test data sizes** - Adjust for your use case
- **Timeout values** - Prevent hanging on slow systems

### Adding New Competitors
To benchmark against additional libraries:

1. Install the competitor: `npm install competitor-lib`
2. Add implementation in relevant benchmark file
3. Update feature matrix in `features/feature-completeness-benchmark.mjs`

## ğŸ¤– CI Integration

### GitHub Actions
The benchmark suite runs automatically:

- **On Pull Requests** - Smoke tests + comparison with main branch
- **On Main Branch** - Full benchmark suite
- **Weekly Schedule** - Regression testing
- **Manual Trigger** - On-demand with custom options

### Benchmark Regression Detection
- Compares PR results with main branch baseline
- Alerts on significant performance regressions
- Tracks feature test success rate changes
- Generates comparison reports

### CI Commands
```bash
# Trigger benchmarks in PR (add to title)
[benchmark] Your PR title

# Manual workflow dispatch with options
# Use GitHub Actions UI to customize which suites run
```

## ğŸ“ˆ Performance Optimization

### Best Practices Tested
- **Streaming vs Buffering** - When to use each approach
- **Concurrent vs Sequential** - Optimal parallelization patterns
- **Memory Management** - Preventing memory leaks in long-running processes
- **Error Handling** - Fast vs robust error management strategies

### Optimization Insights
The benchmarks reveal:
- Stream processing is 2-5x more memory efficient for large data
- Built-in commands avoid process spawning overhead
- Concurrent execution scales well up to CPU core count
- Event patterns add minimal overhead vs direct awaiting

## ğŸ” Troubleshooting

### Common Issues
**Timeouts:**
- Increase timeout values for slow systems
- Skip heavy benchmark suites with `--skip-*` flags

**Memory Issues:**
- Use streaming benchmarks on systems with limited RAM
- Enable garbage collection with `--expose-gc` flag

**Permission Errors:**
- Ensure write access to `benchmarks/results/` directory
- Some tests create temporary files in `/tmp/`

**Missing Dependencies:**
- Install system tools: `jq`, `curl`, `grep`, `awk`
- Ensure Bun/Node.js versions meet requirements

### Debug Mode
```bash
# Enable verbose logging for debugging
COMMAND_STREAM_VERBOSE=true npm run benchmark:features

# Run single test for debugging
cd benchmarks
node -e "
import('./features/feature-completeness-benchmark.mjs')
  .then(m => new m.default())
  .then(b => b.testBasicExecution())
  .then(console.log)
"
```

## ğŸ† Success Metrics

The benchmark suite validates that command-stream provides:

### âœ… Performance Advantages
- **Faster streaming** than buffered alternatives
- **Lower memory usage** for large data processing
- **Competitive process spawning** speed
- **Efficient concurrent execution**

### âœ… Bundle Size Benefits  
- **Smaller footprint** than feature-equivalent alternatives
- **Zero runtime dependencies**
- **Tree-shaking friendly** modular architecture

### âœ… Feature Completeness
- **90%+ feature test success rate**
- **Unique capabilities** not available in competitors
- **Cross-platform compatibility**
- **Runtime flexibility** (Bun + Node.js)

### âœ… Real-World Validation
- **Production-ready** performance in CI/CD scenarios
- **Reliable error handling** under stress
- **Developer workflow optimization**

## ğŸ“š Additional Resources

- **[Main README](../README.md)** - Library documentation
- **[API Reference](../src/$.mjs)** - Source code with examples
- **[Test Suite](../tests/)** - Comprehensive test coverage
- **[CI Configuration](../.github/workflows/)** - Automated testing setup

---

**ğŸŒŸ Help us improve!** If you find issues with the benchmarks or have suggestions for additional tests, please [open an issue](https://github.com/link-foundation/command-stream/issues) or submit a PR.